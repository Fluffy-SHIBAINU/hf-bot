import streamlit as st
import requests
import os
import time

st.set_page_config(page_title="ğŸ§  HF Chatbot", layout="centered")
st.title("ğŸ¤– Hugging Face Chatbot (Multi-Model)")

HF_TOKEN = st.secrets.get("hf_token") or os.getenv("HF_TOKEN")
if not HF_TOKEN:
    st.warning("âš ï¸ Please set your Hugging Face token in Streamlit secrets or as an environment variable (HF_TOKEN)")
    st.stop()

MODELS = {
    "Flan-T5 Small": "google/flan-t5-small",
    "Mistral 7B Instruct": "mistralai/Mistral-7B-Instruct-v0.1",
    "Phi-2": "microsoft/phi-2"
}

with st.sidebar:
    st.header("âš™ï¸ Settings")
    model_choice = st.selectbox("ğŸ§  Model", list(MODELS.keys()))
    if st.button("ğŸ§¹ Clear Chat"):
        st.session_state.messages = []

API_URL = f"https://api-inference.huggingface.co/models/{MODELS[model_choice]}"
headers = {"Authorization": f"Bearer {HF_TOKEN}"}

def query_huggingface(prompt):
    response = requests.post(API_URL, headers=headers, json={"inputs": prompt})
    try:
        return response.json()
    except:
        return [{"generated_text": "[Error in response]"}]

# ì„¸ì…˜ ë©”ì‹œì§€ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì…ë ¥ í¼ (ì±„íŒ… ì•„ë˜ìª½ì— ìœ„ì¹˜)
with st.form("chat_form", clear_on_submit=True):
    user_input = st.text_input("You:")
    submitted = st.form_submit_button("Send")

# ì´ì „ ë©”ì‹œì§€ ì¶œë ¥ (ìµœì‹ ì´ ì•„ë˜ë¡œ)
for sender, msg in st.session_state.messages:
    with st.chat_message("user" if sender == "You" else "assistant"):
        st.markdown(msg)

# ìƒˆ ë©”ì‹œì§€ ì²˜ë¦¬
if submitted and user_input:
    # 1. ìœ ì € ë©”ì‹œì§€ ì¦‰ì‹œ ë Œë”ë§
    with st.chat_message("user"):
        st.markdown(user_input)

    # 2. ë©”ì‹œì§€ ì„¸ì…˜ì— ì¶”ê°€
    st.session_state.messages.append(("You", user_input))

    # 3. context ë§Œë“¤ê¸° (ìµœê·¼ ëŒ€í™” 3ê°œ)
    context = " ".join([msg for sender, msg in st.session_state.messages[-6:] if sender == "You"])
    prompt = context.strip() or user_input

    # 4. API í˜¸ì¶œ
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            result = query_huggingface(prompt)
            reply = result[0].get("generated_text", "[No response]") if isinstance(result, list) else str(result)

        # 5. ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
        response_placeholder = st.empty()
        streamed = ""
        for word in reply.split():
            streamed += word + " "
            response_placeholder.markdown(streamed)
            time.sleep(0.03)

    # 6. ì‘ë‹µ ì €ì¥
    st.session_state.messages.append(("Bot", reply))
